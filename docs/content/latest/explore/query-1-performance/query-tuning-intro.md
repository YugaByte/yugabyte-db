---
title: Introduction to Query Tuning
linkTitle: Introduction
description: Introduction to Query Tuning
aliases:
headerTitle: Introduction to Query Tuning
image: /images/section_icons/index/develop.png
menu:
  latest:
    identifier: query-tuning-intro
    parent: query-tuning
    weight: 150
isTocNested: true
showAsideToc: true
---

Improving the performance of queries in YugabyteDB typically involves some combination of the following general steps:

**1. Find slow queries using pg_stat_statements** 

Use the `pg_stat_statements` extension to get statistics on the execution of queries. Using `pg_stat_statements`, you can quickly track down problematic queries by a variety of criteria, including:

* I/O intensity
* time consumption
* response time
* memory consumption
* temporary space consumption

The [`pg_stat_statements`](https://www.postgresql.org/docs/11/pgstatstatements.html) extension module is installed by default, but must be enabled before you can query the `pg_stat_statements` view.

```sql
CREATE EXTENSION pg_stat_statements;
SELECT query, calls, total_time, min_time, max_time, mean_time, stddev_time, rows FROM pg_stat_statements;
COPY
```

To get the output of `pg_stat_statements` in JSON format, visit `https://<yb-tserver-ip>:13000/statements` in your web browser, where `<yb-tserver-ip>` is the IP address of any YB-TServer node in your cluster.

For more information, see [Get query statistics using `pg_stat_statements`](../pg-stat-statements).

**2. Turn on slow query logging**

Set the `--ysql_log_min_duration_statement` flag to help track down slow queries. When configured, YugabyteDB logs the duration of each completed SQL statement that runs the specified duration (in milliseconds) or longer. (Setting the value to 0 prints all statement durations.)

```sh
$ ./bin/yb-tserver --ysql_log_min_duration_statement 1000
```

Example log output:

```output
2021-05-26 21:13:49.701 EDT [73005] LOG:  duration: 34.378 ms  statement: SELECT c.oid,
        n.nspname,
        c.relname
    FROM pg_catalog.pg_class c
        LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
    WHERE c.relname OPERATOR(pg_catalog.~) '^(products)$'
        AND pg_catalog.pg_table_is_visible(c.oid)
    ORDER BY 2, 3;
```

For more information on flags for configuring the YB-TServer server, see [YSQL Flags](../../../reference/configuration/yb-tserver/#ysql-flags).

**3. View live queries using pg_stat_activity**

Use the `pg_stat_activity` view to get information on currently running tasks. Using `pg_stat_activity` you can troubleshoot problems by identifying long-running idle in transaction sessions or very long running queries.

For more information, see [Viewing live queries with `pg_stat_activity`](../pg-stat-activity).

**4. Understand what your queries are doing with EXPLAIN**

Like PostgreSQL, YugabyteDB provides the `EXPLAIN` statement to show the query execution plan generated by YSQL for a given SQL statement. 

For more information, see [Analyzing queries with EXPLAIN](../explain-analyze).

**5. Evaluate the query for optimization**

Using the information from `EXPLAIN`, decide on the best approach for improving query performance. This could include strategies such as:

* Adding an index
* Changing the primary index
* Changing index sort order

**6. Optimize YSQL queries using pg_hint_plan**

YugabyteDB leverages the PostgreSQL `pg_hint_plan` extension to control query execution plans with hinting phrases using comments.

`pg_hint_plan` makes it possible to tweak execution plans using "hints", which are simple descriptions in the form of SQL comments.

For more information, see [Optimizing YSQL queries using pg_hint_plan](../pg-hint-plan).

## Query tuning example

The following example was drawn from a real-world scenario, where we used the `EXPLAIN` statement to view query plans, and then optimized those queries by adding indexes and adjusting tables.

### Optimizing `SELECT COUNT` using an index

The following table is representative of what the customer was running.

```output
                                    Table "public.contacts"
Column          | Type                           | Collation | Nullable | Default
----------------+--------------------------------+-----------+----------+--------
id              | bigint                         |           | not null |
account_id      | integer                        |           |          |
email           | character varying              |           |          |
first_name      | character varying              |           |          |
last_name       | character varying              |           |          |
address_line_1  | character varying              |           |          |
address_line_2  | character varying              |           |          |
address_city    | character varying              |           |          |
address_state   | character varying              |           |          |
address_postal  | character varying              |           |          |
created_at      | timestamp(6) without time zone |           | not null |
updated_at      | timestamp(6) without time zone |           | not null |
is_over_charged | boolean                        |           |          | false
is_paid         | boolean                        |           |          | false
data_source     | character varying              |           |          |

Indexes:
    "contacts_pkey" PRIMARY KEY, lsm (id HASH)
```

We ran the following queries with `EXPLAIN` output to view the query execution plan generated by YSQL for a given SQL statement.

```sql
yugabyte=# explain SELECT COUNT(*) FROM contacts WHERE contacts.account_id = 1234 
    AND contacts.is_paid = TRUE 
    AND contacts.is_over_chared = TRUE 
    AND (updated_at > '2021-04-12 12:00:00 '); 
```

```output
QUERY PLAN
----------------------------------------------
Aggregate (cost=107.50..107.51 rows=1 width=8)
    Seq Scan on contacts (cost=0.00..105.00 rows=1000 width=0)
        Filter: (is_paid AND is_over_charged AND (updated_at > '2021-04-12 12:00:00'::timestamp without time zone) AND (account_id = 1234))
(3 rows)
```

```sql
yugabyte=# explain SELECT COUNT(*) FROM contacts WHERE contacts.account_id = 5678 
    AND contacts.is_paid_for = TRUE 
    AND contacts.is_over_charged = TRUE 
    AND (updated_at > '2021-04-12 12:00:00');
```

```output
QUERY PLAN
----------------------------------------------
Aggregate (cost=107.50..107.51 rows=1 width=8)
    Seq Scan on contacts (cost=0.00..105.00 rows=1000 width=0)
        Filter: (is_paid AND is_over_charged AND (updated_at > '2021-04-12 12:00:00'::timestamp without time zone) AND (account_id = 5678))
(3 rows)
```

```sql
yugabyte=# explain SELECT COUNT(*) FROM contacts WHERE contacts.account_id = 7890 
    AND contacts.is_paid = FALSE 
    AND (updated_at > '2021-04-12 12:00:00');
```

```output
QUERY PLAN
----------------------------------------------
Aggregate (cost=107.50..107.51 rows=1 width=8)
    Seq Scan on contacts (cost=0.00..105.00 rows=1000 width=0)
        Filter: ((NOT is_paid) AND (updated_at > '2021-04-12 12:00:00'::timestamp without time zone) AND (account_id =1234))
(3 rows)
```

In each case, the queries do a `Seq Scan` (sequential scan) on the tables. This operation requires scanning the entire table to retrieve the desired columns. Even though we are using the partition keys to do the look up, it still needs to do a lot of scanning. 

Generally, you want to avoid `SELECT COUNT(*)` queries as they can require a full scan of the table to get the results. This can cause query degradation and in some cases cause the query to not return at all.

Because most of the queries above use `account_id` as the main qualifier, we can avaoid a sequential scan by creating a direct index on that column, and then use the `INCLUDE` feature to cover the other columns that we also want in the index. Indexing is a powerful tool that can speed up queries with higher latencies. When creating an index, we want to consider the column cardinality, as well as the different index types.

We create the index as follows:

```sql
create index contacts_account_id on contacts (account_id hash, updated_at desc) include (is_paid, is_over_charged);
```

With the index in place, the queries now do an index rather than sequential scan to get the data, significantly improving performance.

```sql
yugabyte=# explain SELECT COUNT(*) FROM contacts WHERE contacts.account_id = 1234 
    AND contacts.is_paid = TRUE 
    AND contacts.is_over_charged = TRUE 
    AND (updated_at > '2021-04-12 12:00:00');
```

```output
QUERY PLAN
------------------------------------------
Aggregate (cost=5.30..5.31 rows=1 width=8)
    Index Scan using contacts_account_id on contacts (cost=0.00..5.28 rows=10 width=0)
    Index Cond: (account_id = 1234)
        Filter: (is_paid AND is_over_charged AND (updated_at > '2021-04-12 12:00:00'::timestamp without time zone))
(4 rows) 

Time: 57.208 ms
Previous run time: 194 seconds
```

```sql
yugabyte=# explain SELECT COUNT(*) FROM contacts WHERE contacts.account_id = 5678 
    AND contacts.is_paid = TRUE 
    AND contacts.is_over_charged = TRUE 
    AND (updated_at > '2021-04-12 12:00:00');
```

```output
QUERY PLAN
------------------------------------------
Aggregate (cost=5.30..5.31 rows=1 width=8)
    Index Scan using contacts_account_id on contacts (cost=0.00..5.28 rows=10 width=0)
    Index Cond: (account_id = 5678)
        Filter: (is_paid AND is_over_charged AND (updated_at > '2021-04-12 12:00:00'::timestamp without time zone))
(4 rows)

Time: 11.923 ms
Previous run time 188 seconds
```

```sql
yugabyte=# explain SELECT COUNT(*) FROM contacts WHERE contacts.account_id = 7890 
    AND contacts.is_paid = FALSE 
    AND (updated_at > '2021-04-12 12:00:00');
```

```output
QUERY PLAN
------------------------------------------
Aggregate (cost=5.30..5.31 rows=1 width=8)
    Index Scan using contacts_account_id on contacts (cost=0.00..5.28 rows=10 width=0)
    Index Cond: (account_id = 8060)
        Filter: ((NOT is_paid) AND (updated_at > '2021-04-12 12:00:00'::timestamp without time zone))
(4 rows)

Time: 46.658 ms
Previous run time: 147 seconds
```

### Optimizing `SELECT` by changing table sorting

The following query retrieves data from an account table where some indexes are already defined.

Table definition:

```sql
yugabyte=# \d accounts
```

```output
                                    Table "public.accounts"
Column        | Type                        | Collation | Nullable | Default
--------------+-----------------------------+-----------+----------+--------
id            | bigint                      | For       | not null | nextval('accounts_id_seq'::regclass)
company_name  | character varying(125)      |           | not null |
status        | character varying(25)       |           |          |
first_name    | character varying(55)       |           |          |
last_name     | character varying(55)       |           |          |
phone         | character varying(25)       |           |          |
created_at    | timestamp without time zone |           | not null |
updated_at    | timestamp without time zone |           | not null |
product_id    | integer                     |           |          |
business_type | character varying(55)       |           |          |
sales_rep     | character varying           |           |          |

Indexes:
    "accounts_pkey" PRIMARY KEY, lsm (id HASH)
    "index_on_company_name" lsm (company_name HASH)
```

`EXPLAIN` output for the query is as follows:

```sql
yugabyte=# explain SELECT accounts.* FROM accounts 
    ORDER BY accounts.id desc, accounts.id desc LIMIT 25 OFFSET 0;
```

```output
QUERY PLAN
----------------------------------------------
Limit (cost=128.22..128.28 rows=25 width=1642)
    Sort (cost=128.22..130.72 rows=1000 width=1642)
        Sort Key: id DESC
            Seq Scan on accounts (cost=0.00..100.00 rows=1000 width=1642)
```

In this case, a sort is run first, which adds extra time to the query, before running a sequential scan of the table, which, as we have seen, also degrades performance.

To optimize this query, we can adjust the sorting of the table by the primary key to be `DESC` rather than `HASH`.

```sql
CREATE TABLE public.accounts ( id bigint NOT NULL, ... ,PRIMARY KEY(id desc);
```

The result is the query no longer does a sequential scan; instead it uses an index scan, cutting execution time from 460ms to 3ms.

```sql
yugabyte=# explain SELECT accounts.* FROM accounts 
    ORDER BY accounts.id desc, accounts.id desc LIMIT 25 OFFSET 0;
```

```output
QUERY PLAN
------------------------------------------
Limit (cost=0.00..2.85 rows=25 width=1642)
    Index Scan using accounts_pkey on accounts (cost=0.00..114.00 rows=1000 width=1642)

Time: 2.994 ms
Previous run time: 426.627 ms
```

### Optimizing `SELECT` using an index

The following example shows another query running a sequential scan, which we can fix by adding an index.

```sql
yugabyte=# \d account_type
```

```output 
                                    Table "public.account_type"
Column      | Type                           | Collation | Nullable | Default
------------+--------------------------------+-----------+----------+--------
id          | bigint                         |           | not null | nextval('account_domains_id_seq'::regclass)
account_id  | integer                        |           | For      |
type        | character varying(55)          |           |          |
url         | character varying              |           |          |
is_valid    | boolean                        |           |          |
created_at  | timestamp(6) without time zone |           | not null |
updated_at  | timestamp(6) without time zone |           | not null |
verified_at | timestamp without time zone    |           |          |

Indexes:
    "account_type_pkey" PRIMARY KEY, lsm (id HASH)
```

```sql
yugabyte=# explain SELECT account_domains.* FROM account_type 
    WHERE account_type.account_id = 1234 ORDER BY account_type.url ASC;
```

```output
QUERY PLAN
----------------------------------------------
Sort (cost=152.33..154.83 rows=1000 width=237)
    Sort Key: url
        Seq Scan on account_type (cost=0.00..102.50 rows=1000 width=237)
            Filter: (account_id = 6873)
```

The query runs a sequential scan on the account_type table, so by adding an index on `account_id`, we can prevent the full scan of the table, as follows:

```sql
create index account_id on account_type(account_id);
```

With the new index, the query scans the index rather than the larger main table, significantly improving performance.

```sql
yugabyte=# explain SELECT account_type.* FROM account_type 
    WHERE account_type.account_id = 6873 ORDER BY account_type.url ASC;
```

```output
QUERY PLAN
----------------------------------------
Sort (cost=5.39..5.42 rows=10 width=237)
    Sort Key: url
        Index Scan using account_id on account_type (cost=0.00..5.22 rows=10 width=237)
            Index Cond: (account_id = 6873)
    
Time: 71.757 ms
Previous runtime: 460 ms
```
